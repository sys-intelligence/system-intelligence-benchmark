mitigation_retry_prompt: |
  Summarize a human-LLM (large language model) conversation by carefully analyzing the interaction, identifying both successes and failures before writing any summaries. For each identified point, select a direct excerpt from the message list that best illustrates or justifies your summary. Then, generate two lists: one of summaries describing what worked well in the conversation, and another of summaries describing what didn’t work or where the interaction was unsuccessful.

  Be sure to:
  - First thoroughly review the entire message list and reason step-by-step to identify all relevant successes and failures before producing any summary points.
  - For **each** bullet point in your lists, include a direct excerpt from the message(s) being referenced. Integrate the excerpt as a supporting quote within the summary bullet, clearly separating the summary from the quoted message.
  - Consider the intentions of the human participant, how well the LLM addressed those goals, communication clarity, misunderstandings, helpfulness, responsiveness, and overall satisfaction.
  - Continue analyzing the conversation until all notable successes and failures are identified.

  Structure your output as follows:
  - First a “What Worked” section, then a “What Didn’t Work” section.
  - Each section should use a markdown header.
  - Use bullet points for each item (2-5 per section). Each bullet point should be succinct (no more than two sentences).
  - Explicitly include a representative excerpt from the conversation in every bullet (formatted as a quote, e.g., “User: ...” or “LLM: ...”).

  # Output Format

  - Use markdown headers: “What Worked” and “What Didn’t Work”.
  - Present 2-5 bullet points per list, each containing both a concise summary and a quoted message excerpt from the conversation.
  - Each bullet may have the structure: Brief summary sentence, followed by a colon and a quoted excerpt.
  - Do not include any extraneous explanation or text.

  # Example

  ### What Worked
  - The LLM accurately interpreted the user's request for a summary: “User: Could you summarize our discussion so far?”
  - The conversation maintained a polite and friendly tone throughout: “LLM: Certainly, I’d be glad to help with that!”

  ### What Didn’t Work
  - The LLM struggled with domain-specific questions, resulting in vague responses: “User: Can you explain how blockchain consensus works?” / “LLM: Blockchain has something to do with security and records, but I’m not sure.”
  - An ambiguous prompt from the user led to confusion early in the exchange: “User: Give me one of those—you know what I mean.”

  _Reminder: Analyze the conversation deeply and include a relevant conversation excerpt with each summary bullet._

localization_summary_prompt: |
  You are a helper agent to an autonomous SRE agent.
  Summarize the agent's trace and output the potential fault location and causes.